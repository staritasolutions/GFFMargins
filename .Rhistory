runApp('Documents/Work/Executive Dashboard/BellaCapelliExecDash')
runApp('Documents/Work/Executive Dashboard/BellaCapelliExecDash')
test_df <- sale_df |> filter(location == "Monroeville") |>
filter(SaleType == "Service") %>%
distinct(location, SaleDate, Client_TId) %>%
count(location, SaleDate) |> View()
test_df <- sale_df |> filter(location == "Monroeville") |>
filter(SaleType == "Service") %>% mutate(SaleDate = floor_date(SaleDate, unit = "month")) |>
distinct(location, SaleDate, Client_TId) %>%
count(location, SaleDate) |> View()
5+8+14+20+4+7+6+15+3+5+14+9+8+18+13+17
library(shiny)
runUrl("https://ajara.byu.edu/STAT651/Lectures/Lecture17.zip")
runApp('Documents/Work/Executive Dashboard/BellaCapelliExecDash')
runApp('Documents/Work/Executive Dashboard/BellaCapelliExecDash')
runApp('Documents/Work/Executive Dashboard/BellaCapelliExecDash')
shiny::runApp('Documents/Work/Executive Dashboard/BellaCapelliExecDash')
runApp('Documents/Work/Executive Dashboard/CincinnatiExecDashv3')
runApp('Documents/Work/Executive Dashboard/ExecDashv3')
runApp('Documents/Work/Executive Dashboard/KanskiExecDashv3')
runApp('Documents/Work/Executive Dashboard/TurnageExecDashv3')
# write the correct code
C <- matrix(c(rep(0,6),1,-1,0,0,0,0,
rep(0,6),1,0,-1,0,0,0,
rep(0,6),1,0,0,-1,0,0,
rep(0,6),1,0,0,0,-1,0,
rep(0,6),1,0,0,0,0,-1), nrow = 5, byrow = TRUE)
C
C2
# write the correct code
C2 <- matrix(c(1,-1,rep(0,10),
0,0,1,-1,rep(0,8),
0,0,0,0,1,-1,rep(0,6),
rep(0,6),1,-1,0,0,0,0,
rep(0,8),1,-1,0,0,
rep(0,10),1,-1), nrow = 6, byrow = TRUE)
C2
multcomp::glht(out, C2, alternative = "two.sided")
#| warning: false
library(tidyverse)
#| warning: false
ChildGrowth <- read_csv("https://grimshawville.byu.edu/ChildGrowth.csv")
ChildGrowth <- ChildGrowth |>
filter(Age < 15) |>
mutate(Gender = factor(Gender),
Ethnicity = factor(Ethnicity))
ChildGrowth |>
group_by(Ethnicity, Gender) |>
summary(n = count(),
Mean_Wt = mean(Weight), StDev_Wt = sd(Weight),
Min_Wt = min(Weight), P10_Wt = quartile(0.10, Weight),
P90_Wt = quartile(0.90, Weight), Max_Wt = max(Weight))
#| echo: false
#| warning: false
ggplot(ChildGrowth,
aes(x = Age,
y = log(Weight))) +
geom_point() +
geom_smooth() +
labs(
main = "Child Growth",
x = "Age (yrs)",
y = "log(Weight) (kg)"
)
ggplot(ChildGrowth,
aes(x = Age,
y = log(Weight),
col = Gender)) +
#geom_point() +
geom_smooth() +
facet_wrap(~ Ethnicity) +
labs(
main = "Child Growth",
x = "Age (yrs)",
y = "log(Weight) (kg)"
)
out <- lm(log(Weight) ~ 0 + (Gender : Ethnicity) + Gender : Ethnicity : Age, data = ChildGrowth, x = TRUE, y = TRUE)
summary(out)
# write the correct code
red.out <- lm(log(Weight) ~ 1 + Age, data = ChildGrowth, x = TRUE, y = TRUE)
summary(red.out)
anova(red.out, out)
# write the correct code
C <- matrix(c(rep(0,6),1,-1,0,0,0,0,
rep(0,6),1,0,-1,0,0,0,
rep(0,6),1,0,0,-1,0,0,
rep(0,6),1,0,0,0,-1,0,
rep(0,6),1,0,0,0,0,-1), nrow = 5, byrow = TRUE)
multcomp::glht(out, C, alternative = "two.sided")
multcomp::glht(out, C2, alternative = "two.sided")
test <- multcomp::glht(out, C2, alternative = "two.sided")
summary(test, test = Ftest())
summary(test, test = multcomp::Ftest())
# write the correct code
red.out <- lm(log(Weight) ~ 1 + Age, data = ChildGrowth, x = TRUE, y = TRUE)
summary(red.out)
head(red.out$x)
shiny::runApp('Documents/Work/Executive Dashboard/ExecDashv3')
runApp('Documents/Work/Executive Dashboard/ExecDashv3')
runApp('Documents/Work/Executive Dashboard/ExecDashv3')
runApp('Documents/Work/Executive Dashboard/TurnageExecDashv3')
runApp('Documents/Work/Executive Dashboard/TurnageExecDashv3')
runApp('Documents/Work/Executive Dashboard/AustinExecDashv3')
shiny::runApp('Documents/Work/Executive Dashboard/ExecDashv3')
library(httr)
library(httpuv)
library(curl)
library(jsonlite)
library(base64enc)
#Client ID and Client Secret were retrieved from the online explorer
clientID <- "ABkqwQRFXtqT9NY9UCJgjaHYoO3IVDwSW80MAqQNs9YJkXpS9E"
clientSecret <- "9kmfk5uFsS7jqyEamv9f1ujHZdx2wRxg741MC6T1"
scope <- "com.intuit.quickbooks.accounting"
RefreshToken <- "AB117082710904HTL2eLk1TF2v58G5mXHPm3naCAmqsx2X3Z8I"
authorize <- base64enc::base64encode(charToRaw(paste0(clientID,":",clientSecret)))
oauth_refresh <- httr::POST("https://oauth.platform.intuit.com/oauth2/v1/tokens/bearer",
add_headers('Content-Type'= "application/x-www-form-urlencoded",
'Accept'= 'application/json',
'Authorization'= paste0('Basic ',authorize)
),
body = list('grant_type'='refresh_token',
'refresh_token'=RefreshToken),
encode = "form")
oaJSON <- fromJSON(content(oauth_refresh, as = "text"))
RefreshToken <- oaJSON[["refresh_token"]][1]
View(oauth_refresh)
authorize
View(oaJSON)
content(oauth_refresh, as = "text")
shiny::runApp('Documents/Work/Executive Dashboard/ExecDashv3')
runApp('Documents/Work/Executive Dashboard/ExecDashv3')
shiny::runApp('Documents/Work/Executive Dashboard/ExecDashv3')
runApp('Documents/Work/Executive Dashboard/ExecDashv3')
?input_switch
runApp('Documents/Work/Executive Dashboard/ExecDashv3')
renv::activate()
renv::stauts
renv::status()
setwd("~/Documents/Work/GFF/MarginsProject")
renv::activate()
renv::status
renv::status()
shiny::runApp('~/Documents/Work/Executive Dashboard/ExecDashv3')
?dateRangeInput
runApp('~/Documents/Work/Executive Dashboard/ExecDashv3')
runApp('~/Documents/Work/Executive Dashboard/ExecDashv3')
runApp('~/Documents/Work/Executive Dashboard/ExecDashv3')
runApp('~/Documents/Work/Executive Dashboard/ExecDashv3')
setwd("~/Documents/Work/Executive Dashboard/ExecDashv3")
source("~/Documents/Work/Executive Dashboard/ExecDashv3/data/crm/crm.R")
runApp()
View(crm_df)
test_df <- crm_df %>% filter(start_date < today())
View(test_df)
test_df %>% count(enroll_status)
crm_df %>% count(enroll_status)
test_df %>% count(workflow_status)
future_df <- crm_df %>% filter(start_date > today())
future_df %>% count(workflow_status)
runApp()
runApp()
runApp()
runApp()
?sym
runApp()
runApp()
test <- "test"
test[1]
test[2]
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
# Set Up ------------------------------------------------------------------
library(dplyr)
library(lubridate)
library(tidymodels)
library(stringr)
library(googlesheets4)
library(janitor)
crm_df <- readRDS("imports/crm/crm_df.rds") %>%
filter(school_name != "Twin Falls") %>%
filter(start_date >= "2024-07-01")
current_estimate_mod <- readRDS("data/models/current_estimate_mod.rds")
adhoc_df <- readRDS("imports/freedom/adhoc_df.rds") # to get last recorded starts
library(tidymodels)
current_estimate_mod <- readRDS("data/models/current_estimate_mod.rds")
adhoc_df <- readRDS("imports/freedom/adhoc_df.rds") # to get last recorded starts
last_adhoc_date <- adhoc_df |>
filter(attend_stat %in% c("Currently Attending", "Leave of Absence", "Suspended")) |>
arrange(start_date) |> tail(1) |> pull(start_date)
leads_preds_df <- readRDS("imports/crm/leadpreds_df.rds") # future start date lead predictions
enrpreds_df <- readRDS("imports/crm/enrpreds_df.rds") |> # future start date predictions
filter(start_date > last_adhoc_date)
enrollment_predictions <- readRDS("data/models/enrollment_predictions.rds") %>%
select(school_name, start_date_name, start_date, program_final, enrollment_pred = pred, n) # past start date fitted values
# Handle Cases where there are multiple start dates for a single start date name
duplicates <- crm_df %>%
distinct(start_date_name, start_date) %>%
count(start_date_name) %>%
filter(n == 2) %>%
pull(start_date_name)
# Define regex patterns for different date formats
patterns <- c(
"\\d{1,2}/\\d{1,2}/\\d{4}",        # Matches dates in M/D/YYYY or MM/DD/YYYY format
"\\b\\d{4}\\b",                    # Matches 4-digit years
"\\b\\w+ \\d{1,2}, \\d{4}\\b"      # Matches dates in "Month DD, YYYY" format
)
# Combine patterns into a single regex pattern
combined_pattern <- paste(patterns, collapse = "|")
# Extract dates using the combined regex pattern
extracted_dates <- str_extract(duplicates, combined_pattern)
# Convert extracted dates to a Date format
convert_to_date <- function(date_str) {
if (is.na(date_str)) {
return(NA)
} else if (str_detect(date_str, "^\\d{4}$")) {
return(as.Date(paste0(date_str, "-01-01"))) # Convert year-only to YYYY-01-01
} else if (str_detect(date_str, "^\\d{1,2}/\\d{1,2}/\\d{4}$")) {
return(mdy(date_str)) # Convert M/D/YYYY or MM/DD/YYYY to Date
} else {
return(mdy(date_str)) # Convert "Month DD, YYYY" to Date
}
}
# Apply the conversion function to the extracted dates
standardized_dates <- as.Date(sapply(extracted_dates, convert_to_date))
duplicates_dates <- tibble(duplicates, standardized_dates)
real_start_dates <- crm_df %>%
select(start_date_name, start_date) %>%
filter(start_date_name %in% duplicates) %>%
left_join(duplicates_dates, by = c("start_date_name" = "duplicates")) %>%
filter(start_date == standardized_dates | is.na(standardized_dates)) %>%
group_by(start_date_name) %>%
slice_head(n = 1) %>%
ungroup() %>%
rename(real_start_date = start_date)
new_crm_df <- crm_df %>%
left_join(real_start_dates, by = "start_date_name") %>%
mutate(start_date = as.Date(ifelse(is.na(real_start_date), start_date, real_start_date)))
# check that there is only 1 start_date for each start_date_name
new_crm_df %>% distinct(start_date_name, start_date) %>%
count(start_date_name) %>%
filter(n > 1)
# function to get snapshot of crm at certain time
get_snapshot <- function(specific_start_date, cutoff_date){
new_df <- new_crm_df %>%
filter(start_date_name == specific_start_date) %>%
mutate(across(c(lead:active, no_longer_interested_date), ~ as.Date(ifelse(.x > cutoff_date, NA, .x))))
return(new_df)
}
get_snapshot_model_df <- function(n_weeks) {
df1 <- new_crm_df %>% distinct(start_date_name, start_date) %>%
filter(!is.na(start_date)) %>%
filter(start_date < today()) %>%
mutate(one_week_before = start_date - weeks(n_weeks)) %>%
mutate(snapshot_data = pmap(list(start_date_name, one_week_before), get_snapshot)) %>%
select(one_week_before, snapshot_data) %>%
unnest(snapshot_data)
# Pre-processing for the model
leadstest_df <- df1 %>%
filter(start_date >= "2024-07-01") %>%
# remove people who aren't interested
filter(is.na(no_longer_interested_date)) %>%
# keep only leads where the date submitted as a lead is before the start date
filter(lead < start_date) %>%
# keep only leads where active date is NA
filter(is.na(active)) %>%
# get a number of days between start to finish
mutate(tot_days = as.numeric(start_date - lead)) %>%
# get number of days until current start date
mutate(days_until_start = as.numeric(start_date - one_week_before)) %>%
# calculate at which point they became a prospect, etc.
mutate(
pros_day = as.numeric(start_date - prospect),
is_pros = ifelse(days_until_start <= pros_day, TRUE, FALSE),
tour_day = as.numeric(start_date - tour),
is_tour = ifelse(days_until_start <= tour_day, TRUE, FALSE),
app_day = as.numeric(start_date - application),
is_app = ifelse(days_until_start <= app_day, TRUE, FALSE),
enrolled_day = as.numeric(start_date - enrolled),
is_enrolled = ifelse(days_until_start <= enrolled_day, TRUE, FALSE)
) %>%
# fill in "is_" columns with NAs with FALSE
mutate(across(starts_with("is_"), ~ ifelse(is.na(.), FALSE, .))) %>%
# group new lead_type categories with something similar
mutate(lead_type = case_when(
lead_type == "Paid - Lead Generators" ~ "Paid - Search PPC",
lead_type == "Website - Top-Level Campaign" ~ "Website - Top-Level",
TRUE ~ lead_type
))
# create predictions
leads_preds <- current_estimate_mod %>%
augment(new_data = leadstest_df, type = "response")
start_date_preds <- leads_preds %>%
group_by(school_name, start_date_name, program_final) %>%
summarize(current_pred = sum(.pred_TRUE)) %>%
left_join(enrollment_predictions,
by = c("school_name", "start_date_name", "program_final"))
enrollment.lm <- lm(n ~ enrollment_pred + current_pred, data = start_date_preds)
return(enrollment.lm)
}
model_results <- tibble(n_weeks = seq(1, 52, by = 1)) %>%
mutate(model_output = pmap(list(n_weeks), get_snapshot_model_df)) # fit along every week going a year back
unique(new_crm_df$lead_type)
get_snapshot_model_df <- function(n_weeks) {
df1 <- new_crm_df %>% distinct(start_date_name, start_date) %>%
filter(!is.na(start_date)) %>%
filter(start_date < today()) %>%
mutate(one_week_before = start_date - weeks(n_weeks)) %>%
mutate(snapshot_data = pmap(list(start_date_name, one_week_before), get_snapshot)) %>%
select(one_week_before, snapshot_data) %>%
unnest(snapshot_data)
# Pre-processing for the model
leadstest_df <- df1 %>%
filter(start_date >= "2024-07-01") %>%
# remove people who aren't interested
filter(is.na(no_longer_interested_date)) %>%
# keep only leads where the date submitted as a lead is before the start date
filter(lead < start_date) %>%
# keep only leads where active date is NA
filter(is.na(active)) %>%
# get a number of days between start to finish
mutate(tot_days = as.numeric(start_date - lead)) %>%
# get number of days until current start date
mutate(days_until_start = as.numeric(start_date - one_week_before)) %>%
# calculate at which point they became a prospect, etc.
mutate(
pros_day = as.numeric(start_date - prospect),
is_pros = ifelse(days_until_start <= pros_day, TRUE, FALSE),
tour_day = as.numeric(start_date - tour),
is_tour = ifelse(days_until_start <= tour_day, TRUE, FALSE),
app_day = as.numeric(start_date - application),
is_app = ifelse(days_until_start <= app_day, TRUE, FALSE),
enrolled_day = as.numeric(start_date - enrolled),
is_enrolled = ifelse(days_until_start <= enrolled_day, TRUE, FALSE)
) %>%
# fill in "is_" columns with NAs with FALSE
mutate(across(starts_with("is_"), ~ ifelse(is.na(.), FALSE, .))) %>%
# group new lead_type categories with something similar
mutate(lead_type = case_when(
lead_type == "Paid - Lead Generators" ~ "Paid - Search PPC",
lead_type == "Website - Top-Level Campaign" ~ "Website - Top-Level",
lead_type == "Other" ~ "Non-Digital",
TRUE ~ lead_type
))
# create predictions
leads_preds <- current_estimate_mod %>%
augment(new_data = leadstest_df, type = "response")
start_date_preds <- leads_preds %>%
group_by(school_name, start_date_name, program_final) %>%
summarize(current_pred = sum(.pred_TRUE)) %>%
left_join(enrollment_predictions,
by = c("school_name", "start_date_name", "program_final"))
enrollment.lm <- lm(n ~ enrollment_pred + current_pred, data = start_date_preds)
return(enrollment.lm)
}
model_results <- tibble(n_weeks = seq(1, 52, by = 1)) %>%
mutate(model_output = pmap(list(n_weeks), get_snapshot_model_df)) # fit along every week going a year back
current_preds <- leads_preds_df %>% group_by(school_name, start_date_name, program_final) %>%
summarize(current_pred = sum(.pred_TRUE))
full_preds <- enrpreds_df %>%
select(school_name, start_date_name, start_date, program_final, enrollment_pred = pred) %>%
left_join(current_preds, by = c("school_name", "start_date_name", "program_final")) %>%
mutate(current_pred = ifelse(is.na(current_pred), 0, current_pred),
weeks_until = ceiling(as.numeric(difftime(start_date, today(), units = "weeks")))) |>
mutate(weeks_until = ifelse(weeks_until <= 0, 1, weeks_until))
# Predict using the model for each entry in full_preds
predict_using_model <- function(input_current_pred, input_enrollment_pred, weeks_until) {
model_row <- model_results %>% filter(n_weeks == weeks_until)
model <- model_row$model_output[[1]]
# Create a dataframe for prediction
new_data <- tibble(current_pred = input_current_pred,
enrollment_pred = input_enrollment_pred)
# Predict using the model
prediction <- predict(model, newdata = new_data)
return(prediction)
}
# Apply the prediction function to full_preds
full_preds <- full_preds %>%
filter(weeks_until <= 52) %>% # only predict for the next year
rowwise() %>%
mutate(predicted_n = round(predict_using_model(current_pred, enrollment_pred, weeks_until))) %>%
select(-current_pred, -enrollment_pred, -weeks_until, pred = predicted_n)
gs4_auth("evan@staritasolutions.com")
caps <- read_sheet("https://docs.google.com/spreadsheets/d/19Lirv-ELUsV9Tel4f3-x1DLsfLNSq-m8iZizh7ERYx8/edit?gid=1358144376#gid=1358144376",
sheet = "Admissions") %>%
select(-c(Track, Goal)) %>%
mutate(Program = case_when(
str_detect(Program, regex("Master Esthetics", ignore_case = TRUE)) ~ "Master Esthetics",
str_detect(Program, regex("barber stylist", ignore_case = TRUE)) ~ "Barber Stylist",
str_detect(Program, regex("barb", ignore_case = TRUE)) ~ "Barber",
str_detect(Program, regex("esth", ignore_case = TRUE)) ~ "Skin",
TRUE ~ Program
)) %>%
mutate(school_name = ifelse(Campus == "CDA", "Coeur d'Alene", Campus)) %>%
select(-Campus) %>%
mutate(Cap = as.numeric(Cap)) %>%
clean_names()
# First identify all groups where the sum of predictions exceeds the cap
groups_over_cap <- full_preds %>%
mutate(temp_program = ifelse(str_detect(start_date_name, "Barber Stylist"), "Barber Stylist", program_final)) %>%
left_join(caps, by = c("school_name", "temp_program" = "program", "start_date" = "start_date")) %>%
group_by(group) %>%
summarize(
sum_pred = sum(pred),
group_cap = mean(cap)  # Renamed to avoid confusion
) %>%
filter(sum_pred > group_cap) %>%
select(group, group_cap)
# Function to adjust predictions based on priority rules
adjust_group_predictions <- function(group_data, group_cap) {
# Get current predictions for each program type
cos_pred <- group_data %>%
filter(temp_program == "Cosmetology") %>%
pull(pred) %>%
{if(length(.) == 0) 0 else .}
bs_pred <- group_data %>%
filter(temp_program == "Barber Stylist") %>%
pull(pred) %>%
{if(length(.) == 0) 0 else .}
barber_pred <- group_data %>%
filter(temp_program == "Barber") %>%
pull(pred) %>%
{if(length(.) == 0) 0 else .}
total_pred <- sum(cos_pred, bs_pred, barber_pred)
overage <- total_pred - group_cap
# Apply adjustment rules
if (overage > 0) {
# Case 1: If Cosmetology is over cap, reduce it to cap and zero out others
if (cos_pred > group_cap) {
group_data <- group_data %>%
mutate(pred = case_when(
temp_program == "Cosmetology" ~ group_cap,
temp_program %in% c("Barber", "Barber Stylist") ~ 0,
TRUE ~ pred
))
}
# Case 2: If Cosmetology + Barber Stylist is over cap, reduce Barber Stylist
else if ((cos_pred + bs_pred) > group_cap) {
new_bs_pred <- max(group_cap - cos_pred, 0)
group_data <- group_data %>%
mutate(pred = case_when(
temp_program == "Barber Stylist" ~ new_bs_pred,
temp_program == "Barber" ~ 0,
TRUE ~ pred
))
}
# Case 3: All three combined are over cap, reduce Barber
else {
new_barber_pred <- max(group_cap - (cos_pred + bs_pred), 0)
group_data <- group_data %>%
mutate(pred = ifelse(temp_program == "Barber", new_barber_pred, pred))
}
}
return(group_data)
}
# Apply adjustments to all over-capacity groups
if(nrow(groups_over_cap) > 0) {
adjusted_groups <- full_preds %>%
mutate(temp_program = ifelse(str_detect(start_date_name, "Barber Stylist"), "Barber Stylist", program_final)) %>%
left_join(caps, by = c("school_name", "temp_program" = "program", "start_date" = "start_date")) %>%
# Join with groups_over_cap to get group_cap (only groups that are over cap)
inner_join(groups_over_cap, by = "group") %>%
# Group by the original group and nest the data
group_by(group) %>%
nest() %>%
# Join with groups_over_cap to get the capacity for each group
left_join(groups_over_cap, by = "group") %>%
# Apply the adjustment function to each group
mutate(adjusted_data = map2(data, group_cap, adjust_group_predictions)) %>%
# Unnest the results
select(group, adjusted_data) %>%
unnest(adjusted_data) %>%
select(-temp_program, -group_cap) %>%
distinct(start_date_name, school_name, program_final, .keep_all = TRUE)
}
# Combine with the non-grouped adjusted predictions
revised_preds <- full_preds %>%
mutate(temp_program = ifelse(str_detect(start_date_name, "Barber Stylist"), "Barber Stylist", program_final)) %>%
left_join(caps, by = c("school_name", "temp_program" = "program", "start_date" = "start_date")) %>%
# Adjust single starts that are over cap
mutate(pred = ifelse(pred < cap | is.na(cap), pred, cap)) %>%
# Remove groups that were over cap (they'll be replaced with adjusted versions)
filter(!group %in% groups_over_cap$group) %>%
select(-temp_program, -cap, -group) %>%
distinct(start_date_name, school_name, program_final, .keep_all = TRUE) %>%
# Add back the adjusted groups
{if(nrow(groups_over_cap) > 0) bind_rows(., adjusted_groups) else .}
saveRDS(revised_preds, "imports/crm/combined_predictions.rds")
if (!requireNamespace("remotes")) {
install.packages("remotes")
}
remotes::install_github("extendr/rextendr")
library(rextender)
library(rextendrr)
library(rextendr)
library(remotes)
remotes::install_github("extendr/rextendr")
